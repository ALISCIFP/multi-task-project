{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Conll Reader\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pdb\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "from tensorflow.models.rnn import rnn_cell\n",
    "from tensorflow.models.rnn import seq2seq\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "##############################\n",
    "# Transform the data into CSV\n",
    "##############################\n",
    "input = open(\"../data/train.txt\", 'rb')\n",
    "output = open(\"../data/train_no_empty_rows.txt\", 'wb')\n",
    "writer = csv.writer(output, lineterminator='\\n')\n",
    "for row in csv.reader(input, delimiter=\" \"):\n",
    "    if row:\n",
    "        writer.writerow(row)\n",
    "input.close()\n",
    "output.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# 1. Build The Graph\n",
    "#######################\n",
    "\n",
    "# Initialise Variables\n",
    "batch_size = 100\n",
    "num_steps = 10\n",
    "size = 10\n",
    "vocab_size = 1000\n",
    "num_layers = 2\n",
    "\n",
    "#########################\n",
    "# 1.1 Placeholders\n",
    "########################\n",
    "\n",
    "# Placeholder for the inputs in a given iteration.\n",
    "words = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "\n",
    "############################\n",
    "# 1.2 Building the Graph \n",
    "###########################\n",
    "\n",
    "# Create LSTM Layers\n",
    "lstm = rnn_cell.BasicLSTMCell(lstm_size,forget_bias=0)\n",
    "cell = rnn_cell.MultiRNNCell([lstm_cell] * num_layers)\n",
    "\n",
    "# Initial state of the LSTM memory.\n",
    "initial_state = tf.zeros([batch_size, lstm.state_size])\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    embedding = tf.get_variable(\"embedding\", [vocab_size, size])\n",
    "    inputs = tf.nn.embedding_lookup(embedding, self._input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data Reader\n",
    "def _read_single_line(filename_queue):\n",
    "    reader = tf.TextLineReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "\n",
    "    # These set the default types for the decoder, and the default value ('P')\n",
    "    record_defaults = [tf.constant(['p'], dtype=tf.string),    # Column 0\n",
    "                       tf.constant(['p'], dtype=tf.string),    # Column 1\n",
    "                       tf.constant(['p'], dtype=tf.string)]    # Column 2\n",
    "    # decode a line\n",
    "    word, pos, chunk = tf.decode_csv(\n",
    "        value, record_defaults=record_defaults)\n",
    "    \n",
    "    # Use pack instead of concatenate because scalars\n",
    "    features = tf.pack([pos, chunk])\n",
    "    return [word, features]\n",
    "\n",
    "def input_pipeline(batch_size, read_threads=1, num_epochs=None):\n",
    "    filename_queue = tf.train.string_input_producer([\"../data/train_no_empty_rows.txt\"])\n",
    "    example, features = _read_single_line(filename_queue)\n",
    "    \n",
    "    # min_after_dequeue defines how big a buffer we will randomly sample\n",
    "    #   from -- bigger means better shuffling but slower start up and more\n",
    "    #   memory used.\n",
    "    # capacity must be larger than min_after_dequeue and the amount larger\n",
    "    #   determines the maximum we will prefetch.  Recommendation:\n",
    "    #   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "    \n",
    "    min_after_dequeue = 1000\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    example_batch, label_batch = tf.train.shuffle_batch(\n",
    "      [example, label], batch_size=batch_size, capacity=capacity,\n",
    "      min_after_dequeue=min_after_dequeue)\n",
    "    return example_batch, label_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-b37d20aaf793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Placeholder for the inputs in a given iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
